{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6da3664",
   "metadata": {},
   "source": [
    "# Compute MHWs from moored in situ temperature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e59bf3",
   "metadata": {},
   "source": [
    "The goal of the code is to compute Marine Heatwaves (MHWs) from daily temperature time-series data obtained from the ORS065 mooring. It processes the data by selecting the input files, gridding the mooring data onto a regular grid (still daily, but with specific start and date), and then applying the MHW detection algorithm. The detected MHW events are analyzed and relevant information is saved in a shelf file for further analysis. The code iterates over multiple files, each representing a different depth, to perform the analysis and save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2379fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import glob\n",
    "import shelve\n",
    "import marineHeatWaves_AS_v2 as mhw_v2\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import date\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8158fb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "list_FILES = sorted(glob.glob('./DATA_raw_mooring_ORS065/file_ORS065*_NEWdepths.csv'))\n",
    "N_FILES = len(list_FILES)\n",
    "print(N_FILES)\n",
    "\n",
    "ClimatologyPeriod = [1992, 2019]\n",
    "MHWPeriod = [1992, 2019]\n",
    "mhwname = 'MHWS_2020'\n",
    "\n",
    "# Create a regular daily time vector from 1 Jan 1992 to 31 Dec 2019\n",
    "times_dates = np.arange(\n",
    "    datetime.datetime(ClimatologyPeriod[0], 1, 1),\n",
    "    datetime.datetime(ClimatologyPeriod[1] + 1, 1, 1),\n",
    "    datetime.timedelta(days=1)\n",
    ").astype(datetime.datetime)\n",
    "t = np.array([times_dates[i].toordinal() for i in range(len(times_dates))])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c752b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the mooring data\n",
    "def fun_getdata(FILE):\n",
    "    my_data_str = np.genfromtxt(FILE, delimiter=',', dtype='str')\n",
    "    depth = int(my_data_str[1, 0])\n",
    "    T = len(my_data_str) - 1  # 0 is the title\n",
    "    format = \"%Y-%m-%d\"\n",
    "\n",
    "    times_dates0 = np.array([datetime.datetime.strptime(my_data_str[i, 1], format) for i in range(1, T)]) # 0 is the title\n",
    "    t0 = np.array([times_dates0[i].toordinal() for i in range(len(times_dates0))])\n",
    "    sst0 = np.array([float(my_data_str[i, 2]) for i in range(1, T)]) # 0 is the title\n",
    "        \n",
    "    return depth, t0, times_dates0, sst0\n",
    "\n",
    "# Function to match the mooring data with a regular grid\n",
    "def fun_interp(t0, sst0, t):\n",
    "    # Interpolate onto regular grid\n",
    "    sst = np.zeros(len(t)) + np.nan\n",
    "    t0_day = np.int0(t0)\n",
    "    for i in range(len(t)):\n",
    "        # Match day-of-year values and average if the resolution is higher than daily\n",
    "        t0_ind = np.where(t0_day == t[i])[0]\n",
    "        if np.isfinite(t0_ind):\n",
    "            sst[i] = np.nanmean(sst0[t0_ind.astype(int)])\n",
    "     \n",
    "    # Calculate the percentage of days with NaN values\n",
    "    Nb_nans = np.sum(np.isnan(sst)) / len(sst)\n",
    "    print('Percentage of NaN= ' + str(Nb_nans))\n",
    "    \n",
    "    return times_dates, sst, Nb_nans\n",
    "\n",
    "# Function to create a time-series with the MHW information\n",
    "def fun_get_ano_timeseries(sst, clim, mhws):\n",
    "    sst_ano_thresh = sst - clim['thresh']\n",
    "    sst_ano = sst - clim['seas']\n",
    "\n",
    "    # More time-series\n",
    "    sst_ano_pos = sst * 0  # only for positive anomalies\n",
    "    list_MHWstats_1_0 = sst * 0  # list of 0, same size as list_sst\n",
    "\n",
    "    # Fill values only when MHW\n",
    "    for i in range(mhws['n_events']):\n",
    "        ind_MHW = np.array(range(mhws['index_start'][i], mhws['index_end'][i] + 1))\n",
    "        list_MHWstats_1_0[ind_MHW] = 1\n",
    "        sst_ano_pos[ind_MHW] = sst_ano[ind_MHW]  # only for positive anomalies\n",
    "\n",
    "    # Add data to the clim dictionary\n",
    "    clim['sst'] = sst\n",
    "    clim['times_dates'] = times_dates\n",
    "    clim['t'] = t\n",
    "    clim['list_MHWstats_1_0'] = list_MHWstats_1_0\n",
    "    clim['sst_ano_thresh'] = sst_ano_thresh\n",
    "    clim['sst_ano'] = sst_ano\n",
    "    \n",
    "    return sst_ano, sst_ano_thresh, sst_ano_pos, sst_ano_pos, list_MHWstats_1_0\n",
    "\n",
    "# Function to save the data in a shelf\n",
    "def fun_save_shelf(mhws, clim, dict_year_stats, depth):\n",
    "    depth_order = '0' + str(depth)\n",
    "    with shelve.open('DATA_processed/SAVE_ORS065_mhws_Strength2018' + '_z' + str(depth_order[-2:])) as d:\n",
    "        d['dict_mhws'] = mhws\n",
    "        d['dict_clim'] = clim\n",
    "        d['dict_year_stats'] = dict_year_stats\n",
    "        d['DEPTHS'] = depth\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa2f10f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to match the mooring data with a regular grid\n",
    "def fun_stats_years_months_days_WinterSummer(t,mhws,depth,list_MHWstats_1_0,dict_year_stats):\n",
    "    colours = (plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "    t_all_MHWdays = t[np.where(list_MHWstats_1_0==1)]\n",
    "    \n",
    "    # Create dataframe\n",
    "    df_ORS_all_daily=pd.DataFrame(list_MHWstats_1_0,pd.DatetimeIndex(times_dates, name='t'))\n",
    "    df_ORS_all_daily.columns = ['MHWdays']\n",
    "\n",
    "    ### Seasons 3 months\n",
    "    winter_3m = ((df_ORS_all_daily.index.month >6) & (df_ORS_all_daily.index.month <10)) # June - Aug\n",
    "    summer_3m = ((df_ORS_all_daily.index.month <4)) # Jan - Mar # \n",
    "\n",
    "\n",
    "    df_ORS_all_yearly_MHWdays_year = df_ORS_all_daily.groupby(df_ORS_all_daily.index.year).sum()\n",
    "    df_ORS_all_yearly_MHWdays_winter_3m = df_ORS_all_daily[winter_3m].groupby(df_ORS_all_daily[winter_3m].index.year).sum()\n",
    "    df_ORS_all_yearly_MHWdays_summer_3m = df_ORS_all_daily[summer_3m].groupby(df_ORS_all_daily[summer_3m].index.year).sum()\n",
    "    \n",
    "    dict_year_stats['n_days_years_winter2_3m'] = np.array(df_ORS_all_yearly_MHWdays_winter_3m['MHWdays'])\n",
    "    dict_year_stats['n_days_years_summer2_3m'] = np.array(df_ORS_all_yearly_MHWdays_summer_3m['MHWdays'])\n",
    "\n",
    "    dict_year_stats['t'] = t\n",
    "    dict_year_stats['years'] = np.array(df_ORS_all_yearly_MHWdays_year.index  )\n",
    "    dict_year_stats['n_days_years'] = np.array(df_ORS_all_yearly_MHWdays_year['MHWdays'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f434ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./DATA_raw_mooring_ORS065\\file_ORS065_temp_Z001_NEWdepths.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amandine\\AppData\\Local\\Temp\\ipykernel_10616\\2534439008.py:18: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  t0_day = np.int0(t0)\n",
      "C:\\Users\\Amandine\\AppData\\Local\\Temp\\ipykernel_10616\\2534439008.py:23: RuntimeWarning: Mean of empty slice\n",
      "  sst[i] = np.nanmean(sst0[t0_ind.astype(int)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaN= 0.6167986701867605\n",
      "./DATA_raw_mooring_ORS065\\file_ORS065_temp_Z005_NEWdepths.csv\n",
      "Percentage of NaN= 0.6167986701867605\n",
      "./DATA_raw_mooring_ORS065\\file_ORS065_temp_Z010_NEWdepths.csv\n",
      "Percentage of NaN= 0.6167008898015058\n",
      "./DATA_raw_mooring_ORS065\\file_ORS065_temp_Z015_NEWdepths.csv\n",
      "Percentage of NaN= 0.28297643492715363\n",
      "./DATA_raw_mooring_ORS065\\file_ORS065_temp_Z020_NEWdepths.csv\n",
      "Percentage of NaN= 0.16828004302336952\n",
      "./DATA_raw_mooring_ORS065\\file_ORS065_temp_Z025_NEWdepths.csv\n",
      "Percentage of NaN= 0.17287572113034125\n",
      "./DATA_raw_mooring_ORS065\\file_ORS065_temp_Z030_NEWdepths.csv\n",
      "Percentage of NaN= 0.16818226263811478\n",
      "./DATA_raw_mooring_ORS065\\file_ORS065_temp_Z035_NEWdepths.csv\n",
      "Percentage of NaN= 0.16593331377725629\n",
      "./DATA_raw_mooring_ORS065\\file_ORS065_temp_Z040_NEWdepths.csv\n",
      "Percentage of NaN= 0.16642221570352989\n",
      "./DATA_raw_mooring_ORS065\\file_ORS065_temp_Z045_NEWdepths.csv\n",
      "Percentage of NaN= 0.16837782340862423\n",
      "./DATA_raw_mooring_ORS065\\file_ORS065_temp_Z050_NEWdepths.csv\n",
      "Percentage of NaN= 0.196538574361983\n",
      "./DATA_raw_mooring_ORS065\\file_ORS065_temp_Z053_NEWdepths.csv\n",
      "Percentage of NaN= 0.18529383005769043\n"
     ]
    }
   ],
   "source": [
    "# Loop over each file\n",
    "for f in range(N_FILES):\n",
    "    FILE = list_FILES[f]\n",
    "    print(FILE)\n",
    "\n",
    "    dict_year_stats = {} \n",
    "    depth, t0, times_dates0, sst0 = fun_getdata(FILE)\n",
    "    times_dates, sst, Nb_nans = fun_interp(t0, sst0, t)\n",
    "    dict_year_stats = {}\n",
    "    \n",
    "    ## Run MHW algorithm from Hobday et al, 2016 and https://github.com/ecjoliver/marineHeatWaves  \n",
    "    mhws, clim = mhw_v2.detect(t, sst, climatologyPeriod=ClimatologyPeriod, MHWPeriod=MHWPeriod, smoothPercentileWidth=31)\n",
    "    sst[clim['missing']] = np.nan  # reverse the padding of sst\n",
    "\n",
    "    # Re-format into time-series\n",
    "    sst_ano, sst_ano_thresh, sst_ano_pos, sst_ano_pos, list_MHWstats_1_0 = fun_get_ano_timeseries(sst, clim, mhws)\n",
    "\n",
    "    fun_stats_years_months_days_WinterSummer(t,mhws,depth,list_MHWstats_1_0,dict_year_stats)\n",
    "\n",
    "    \n",
    "    # Save data\n",
    "    fun_save_shelf(mhws, clim, dict_year_stats, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5b9edd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
